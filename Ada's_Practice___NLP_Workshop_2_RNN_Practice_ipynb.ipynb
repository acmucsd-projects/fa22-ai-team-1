{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recurring Neural Nets for NLP\n"
      ],
      "metadata": {
        "id": "0RePEUK_vft2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Setup & Exploration\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L7lFKa7lvrR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a. Setup** "
      ],
      "metadata": {
        "id": "V6EyWc_r7M5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "!mkdir -p /content/emotion-sentiment\n",
        "%cd /content/emotion-sentiment\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1EFpJf3GblKvBzutrykHZvoBVPdqFrTh_')\n",
        "!unzip -q archive.zip\n",
        "!rm -q archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdRppnCQwC62",
        "outputId": "e5abed05-84a1-4510-d960-ce50d340b7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/emotion-sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1EFpJf3GblKvBzutrykHZvoBVPdqFrTh_\n",
            "To: /content/emotion-sentiment/archive.zip\n",
            "100%|██████████| 738k/738k [00:00<00:00, 44.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: invalid option -- 'q'\n",
            "Try 'rm --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "y7BoVVci5PnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten, Dropout"
      ],
      "metadata": {
        "id": "E-JECoje5W2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data with pandas"
      ],
      "metadata": {
        "id": "av8sQ8SA8VY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/emotion-sentiment/test.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding =\"utf-8\")\n",
        "train_data = pd.read_csv(\"/content/emotion-sentiment/train.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding =\"utf-8\")\n",
        "validation_data = pd.read_csv(\"/content/emotion-sentiment/val.txt\", header=None, sep=\";\", names=[\"Comment\",\"Emotion\"], encoding =\"utf-8\")"
      ],
      "metadata": {
        "id": "MZFZmlxs8XbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Exploration"
      ],
      "metadata": {
        "id": "LJTc5Ra6HtIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3 portions to the data: the train set, to train our model with, the validation data, to check how well our model performs, and the test data, to test our model's performance on random, wild data.\n",
        "\n",
        "Examining the size of the data we are given:"
      ],
      "metadata": {
        "id": "FTKi-tDlv8xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train size:\\t\", train_data.shape)\n",
        "print(\"Test size:\\t\", test_data.shape)\n",
        "print(\"Validation size:\\t\", validation_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vovkiNWXu84v",
        "outputId": "342f9182-6570-45b3-aa01-19d3c5b3f82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:\t (16000, 2)\n",
            "Test size:\t (2000, 2)\n",
            "Validation size:\t (2000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "contents of data"
      ],
      "metadata": {
        "id": "gCcWcjwL4fdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EsF7IaSn4hMO",
        "outputId": "633392a9-3381-4a0e-b045-c65858443ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Comment  Emotion\n",
              "0                                i didnt feel humiliated  sadness\n",
              "1      i can go from feeling so hopeless to so damned...  sadness\n",
              "2       im grabbing a minute to post i feel greedy wrong    anger\n",
              "3      i am ever feeling nostalgic about the fireplac...     love\n",
              "4                                   i am feeling grouchy    anger\n",
              "...                                                  ...      ...\n",
              "15995  i just had a very brief time in the beanbag an...  sadness\n",
              "15996  i am now turning and i feel pathetic that i am...  sadness\n",
              "15997                     i feel strong and good overall      joy\n",
              "15998  i feel like this was such a rude comment and i...    anger\n",
              "15999  i know a lot but i feel so stupid because i ca...  sadness\n",
              "\n",
              "[16000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b383d9b4-ac8b-4158-92a3-cdbfc3a17513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>i just had a very brief time in the beanbag an...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>i am now turning and i feel pathetic that i am...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>i feel strong and good overall</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>i feel like this was such a rude comment and i...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b383d9b4-ac8b-4158-92a3-cdbfc3a17513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b383d9b4-ac8b-4158-92a3-cdbfc3a17513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b383d9b4-ac8b-4158-92a3-cdbfc3a17513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the emotions labeling the comments?"
      ],
      "metadata": {
        "id": "cymvlq5e5JxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[\"Emotion\"].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO7o0-ND5Nrq",
        "outputId": "7c9e8da1-9635-4e80-d17b-b0d6bd1b5a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sadness' 'anger' 'love' 'surprise' 'fear' 'joy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> there are six classes of emotions, so we must train an multi-class classification model\n",
        "  \n",
        "  ❓What is a **multi-class classification**?\n",
        "\n",
        " **multi-class classification:**\n",
        "  classifying instances into more than 2 instances"
      ],
      "metadata": {
        "id": "LfTUB8o35dOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Preprocessing"
      ],
      "metadata": {
        "id": "qopoS9fn6nYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##a. Dataset Modifications"
      ],
      "metadata": {
        "id": "q6VqHSqc65Dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding a new column of data containing the length of each comment to training data"
      ],
      "metadata": {
        "id": "ZqGJoLp-68Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"Length\"] = [len(x) for x in train_data[\"Comment\"]]"
      ],
      "metadata": {
        "id": "Js3iUVqO6ibx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing emotions with integer representations"
      ],
      "metadata": {
        "id": "6UdsRLqS7T0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder()\n",
        "train_data['Emotion'] = lb.fit_transform(train_data['Emotion'])\n",
        "test_data['Emotion'] = lb.fit_transform(test_data['Emotion'])\n",
        "validation_data['Emotion'] = lb.fit_transform(validation_data['Emotion'])"
      ],
      "metadata": {
        "id": "u65F6Fmn7bFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modified train_data:"
      ],
      "metadata": {
        "id": "g7WPCl4G8aD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ExDeLQNo8cNn",
        "outputId": "064b9547-cfc6-4e1e-f6f2-c34fa823bc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Comment  Emotion  Length\n",
              "0                                i didnt feel humiliated        4      23\n",
              "1      i can go from feeling so hopeless to so damned...        4     108\n",
              "2       im grabbing a minute to post i feel greedy wrong        0      48\n",
              "3      i am ever feeling nostalgic about the fireplac...        3      92\n",
              "4                                   i am feeling grouchy        0      20\n",
              "...                                                  ...      ...     ...\n",
              "15995  i just had a very brief time in the beanbag an...        4     101\n",
              "15996  i am now turning and i feel pathetic that i am...        4     102\n",
              "15997                     i feel strong and good overall        2      30\n",
              "15998  i feel like this was such a rude comment and i...        0      59\n",
              "15999  i know a lot but i feel so stupid because i ca...        4      62\n",
              "\n",
              "[16000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8456dfaa-9462-4853-b4bd-815698000173\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>4</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>3</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>i just had a very brief time in the beanbag an...</td>\n",
              "      <td>4</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>i am now turning and i feel pathetic that i am...</td>\n",
              "      <td>4</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>i feel strong and good overall</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>i feel like this was such a rude comment and i...</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8456dfaa-9462-4853-b4bd-815698000173')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8456dfaa-9462-4853-b4bd-815698000173 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8456dfaa-9462-4853-b4bd-815698000173');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##b. Data Cleaning"
      ],
      "metadata": {
        "id": "Z9xMQ-iYNbO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few techniques for cleaning text data"
      ],
      "metadata": {
        "id": "gycYFXidNgwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###i. Stop Words"
      ],
      "metadata": {
        "id": "iQn_cKqxNwXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ntlk stop word list"
      ],
      "metadata": {
        "id": "JY7KvdxzOKsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['Caleb brought some donuts and is driving', 'He is very kind for doing all that']\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "print()\n",
        "\n",
        "for sentence in sentences:\n",
        "  stopped = \" \".join([word for word in sentence.split() if word not in stopwords])\n",
        "  print(f\"{sentence}\\n{stopped}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgwBX4w1OFHP",
        "outputId": "9a567931-b3d5-4724-d49d-52cfa2f11489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Caleb brought some donuts and is driving\n",
            "Caleb brought donuts driving\n",
            "\n",
            "He is very kind for doing all that\n",
            "He kind\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ii.Stemming"
      ],
      "metadata": {
        "id": "BLjQunfdRxzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "taking suffixes and prefixes out of words, chnaging singular to plural and vice versa, etc"
      ],
      "metadata": {
        "id": "iGcjPX3pSaI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['Caleb brought some donuts and is driving', 'He is running and jumping']\n",
        "stemmer = PorterStemmer()\n",
        "for sentence in sentences:\n",
        "  stemmed = \" \".join([stemmer.stem(word) for word in sentence.split()])\n",
        "  print(f\"{sentence}\\n{stemmed}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFObvaA3St0_",
        "outputId": "ded98e8c-081f-4cdd-f146-f15c9baca4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caleb brought some donuts and is driving\n",
            "caleb brought some donut and is drive\n",
            "\n",
            "He is running and jumping\n",
            "he is run and jump\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###iii. one-hot encoding"
      ],
      "metadata": {
        "id": "GLAX-G4rTX86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensorflow function assigning words to randomly generated numbers from 1-10. Padding will be added to shorter sentences to match the longest one in the array"
      ],
      "metadata": {
        "id": "rXpb1kaPTatt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"Caleb ate some donuts\", \"Caleb ate some\",\"Some ate\"]\n",
        "max_len = max([len(sentence.split()) for sentence in sentences])\n",
        "encoded = []\n",
        "for sentence in sentences:\n",
        "  encoded.append(one_hot(input_text=sentence, n=20))\n",
        "\n",
        "padded = pad_sequences(sequences=encoded, maxlen=max_len,padding=\"pre\")\n",
        "\n",
        "#converts text into number vectors\n",
        "for i in range(len(padded)): print(f\"{sentences[i]}\\n{padded[i]}\\n\")\n"
      ],
      "metadata": {
        "id": "l34qJkBqTx_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c534b76-250f-418c-9ef2-ff72ed95f5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caleb ate some donuts\n",
            "[17  4 15  8]\n",
            "\n",
            "Caleb ate some\n",
            "[ 0 17  4 15]\n",
            "\n",
            "Some ate\n",
            "[ 0  0 15  4]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step: incorporating all the above techniques into a function called\n",
        "    **text_cleaning**  \n",
        "\n",
        "This function will:\n",
        "1. remove special characters\n",
        "2. convert everything to lowercase\n",
        "3. remove stop words\n",
        "4. stem all the text\n",
        "5. one-hot encode all the sentences\n",
        "\n",
        "This will ultimately convert the text into a format usable by the model -> the aim of **preprocessing**"
      ],
      "metadata": {
        "id": "rg3KG9-1z2Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1100\n",
        "max_len = train_data['Length'].max()\n",
        "\n",
        "#downloading stopwords from nltk and saving them for use\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "#the text_cleaning function\n",
        "def text_cleaning(df,column):\n",
        "\n",
        "  \"\"\"Removing irrelevant characters, stemming, and padding\"\"\"\n",
        "  stemmer = PorterStemmer()\n",
        "  corpus = []\n",
        "\n",
        "  for text in df[column]:\n",
        "    #converts to lowercase & removes special chars\n",
        "    text = text_to_word_sequence(text)\n",
        "\n",
        "    #apply stemming while removing stop words\n",
        "    text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
        "    text = \" \".join(text)\n",
        "\n",
        "    corpus.append(text)\n",
        "\n",
        "  #one-hot encode each sentence (convert it into a vector)\n",
        "  one_hot_word = [one_hot(input_text=sentence,n=vocab_size) for sentence in corpus]\n",
        "  #apply padding to make all vector representations of sentences of equal length\n",
        "  pad = pad_sequences(sequences=one_hot_word,maxlen=max_len,padding='pre')\n",
        "\n",
        "  return pad\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXGF9W570ts4",
        "outputId": "adc7cf44-4ed1-4c2e-df83-068f8057a3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, it's time to apply this function to clean up the data in our dataset"
      ],
      "metadata": {
        "id": "yKcWwmDY7zs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = text_cleaning(train_data, \"Comment\")\n",
        "x_test = text_cleaning(test_data,\"Comment\")\n",
        "x_val = text_cleaning(validation_data,\"Comment\")"
      ],
      "metadata": {
        "id": "Cv6ebChu7y8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpn-IYs8Sk9",
        "outputId": "5714c0f9-8fce-4b6f-9885-293397eecbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ... 917 137  76]\n",
            " [  0   0   0 ... 172 759 869]\n",
            " [  0   0   0 ... 137 725 974]\n",
            " ...\n",
            " [  0   0   0 ... 816 719 301]\n",
            " [  0   0   0 ... 284 437 772]\n",
            " [  0   0   0 ... 137 183 554]]\n",
            "(16000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1600 sentences are in the training dataset. Next step: create \n",
        "    **y_train**\n",
        "  , \n",
        "    **y_val**\n",
        "  , and \n",
        "    **y_test** \n",
        "  out of the emotion labels (we need these to see how well the model predicts the emotion behind each sentence)."
      ],
      "metadata": {
        "id": "dCpIIvhW85ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the emotion columns into arrays\n",
        "y_train_nums = train_data[\"Emotion\"]\n",
        "y_val_nums = validation_data[\"Emotion\"]\n",
        "y_test_nums = test_data[\"Emotion\"]\n",
        "\n",
        "#creating training values as vectors (to categorical employs traditional one-hot encoding to convert the emotion values into vectors)\n",
        "y_train = to_categorical(y_train_nums)\n",
        "y_val = to_categorical(y_val_nums)\n",
        "y_test = to_categorical(y_test_nums)\n",
        "\n",
        "print(\"As numbers:\\n\" + str(y_train_nums.head(5)))\n",
        "print()\n",
        "print(\"As vectors:\\n\"+str(y_train[0:5]))\n",
        "\n",
        "print()\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_00M19Z_9PaN",
        "outputId": "9e79c019-e22e-4e58-dfe8-0b79983421b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As numbers:\n",
            "0    4\n",
            "1    4\n",
            "2    0\n",
            "3    3\n",
            "4    0\n",
            "Name: Emotion, dtype: int64\n",
            "\n",
            "As vectors:\n",
            "[[0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "(16000, 6)\n",
            "(2000, 6)\n",
            "(2000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Modeling Recurring Neural Networks"
      ],
      "metadata": {
        "id": "QZzkhy7xBMIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard neural nets are \"forward-pass\", meaning they look at data in an isolated environment. They do not remember prior pieces of data.\n",
        "\n",
        "**Sequential data:** Where data points rely on other pieces of data\n",
        "\n",
        "i.e. a sentence: the meaning of the words depends on the context of the sentence, or what other words are in the sentence\n",
        "\n",
        "**Recurrent Neural Network:** A type of neural network that is built to process sequential data (it comes with internal memory!)\n",
        "\n",
        "RNNs process sequence input by iterating through the elements. They pass output from one timestep to the input of the next timestep.\n"
      ],
      "metadata": {
        "id": "9aBKZjCQD9Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Layers of our neural net:\n",
        "1. Embedding: maps output into a latent space smaller than vocab\n",
        "2. Dropout: zeros out some neurons to avoid overfitting\n",
        "3. SimpleRNN: a simple RNN with a few hidden layers interacting\n",
        "4. Dense: layer of neurons outputing a tensor of specific size"
      ],
      "metadata": {
        "id": "6qYOFgg1JYTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  #putting words in a smaller latent space to make the sentences easier to process\n",
        "  model.add(Embedding(input_dim=vocab_size,input_length=max_len,output_dim=150))\n",
        "  #adding Dropout layer to prevent overfitting\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(SimpleRNN(128))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(64,activation='sigmoid'))\n",
        "  model.add(Dropout(0.2))\n",
        "      #use Dense(6, activation='softmax') because we have 6 classes (6 emotions) so a tensor of dimension 6 is generated\n",
        "  model.add(Dense(6, activation = 'softmax'))\n",
        "      #softmax takes in classes and returns a probability decimal for each of them, totaling to 1\n",
        "  \n",
        "  model.compile(optimizer='Adam',loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy',\n",
        "                                                                                   tf.keras.metrics.Precision(),\n",
        "                                                                                   tf.keras.metrics.Recall()])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "Pu3J7piELW-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next: training the model using .fit()"
      ],
      "metadata": {
        "id": "Yfef4Wb6Pmm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n"
      ],
      "metadata": {
        "id": "TGmSBTGcPpF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train,y_train,epochs=10,batch_size=64,\n",
        "                 validation_data=(x_val,y_val), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KYTLzbgRXTs",
        "outputId": "f82d69e8-5cfa-4758-94fa-12122b79d7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 55s 214ms/step - loss: 1.6150 - accuracy: 0.3183 - precision_1: 0.2894 - recall_1: 0.0049 - val_loss: 1.5696 - val_accuracy: 0.3555 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 52s 210ms/step - loss: 1.3823 - accuracy: 0.4816 - precision_1: 0.6521 - recall_1: 0.2319 - val_loss: 1.1400 - val_accuracy: 0.6050 - val_precision_1: 0.7046 - val_recall_1: 0.4270\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 51s 205ms/step - loss: 1.0104 - accuracy: 0.6584 - precision_1: 0.7370 - recall_1: 0.5437 - val_loss: 1.0300 - val_accuracy: 0.6400 - val_precision_1: 0.7314 - val_recall_1: 0.5405\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 51s 205ms/step - loss: 0.8264 - accuracy: 0.7203 - precision_1: 0.7748 - recall_1: 0.6544 - val_loss: 0.7962 - val_accuracy: 0.7210 - val_precision_1: 0.7627 - val_recall_1: 0.6700\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 50s 199ms/step - loss: 0.8328 - accuracy: 0.7103 - precision_1: 0.7684 - recall_1: 0.6406 - val_loss: 0.9391 - val_accuracy: 0.6640 - val_precision_1: 0.7479 - val_recall_1: 0.5830\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 51s 204ms/step - loss: 0.7502 - accuracy: 0.7444 - precision_1: 0.8004 - recall_1: 0.6809 - val_loss: 0.7526 - val_accuracy: 0.7425 - val_precision_1: 0.7889 - val_recall_1: 0.6820\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 52s 208ms/step - loss: 0.6499 - accuracy: 0.7723 - precision_1: 0.8161 - recall_1: 0.7241 - val_loss: 0.7110 - val_accuracy: 0.7500 - val_precision_1: 0.7937 - val_recall_1: 0.7080\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 51s 204ms/step - loss: 0.8274 - accuracy: 0.7134 - precision_1: 0.7716 - recall_1: 0.6492 - val_loss: 0.8073 - val_accuracy: 0.7210 - val_precision_1: 0.7747 - val_recall_1: 0.6635\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 50s 199ms/step - loss: 0.6684 - accuracy: 0.7694 - precision_1: 0.8057 - recall_1: 0.7229 - val_loss: 0.7121 - val_accuracy: 0.7465 - val_precision_1: 0.7826 - val_recall_1: 0.7145\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 51s 206ms/step - loss: 0.5894 - accuracy: 0.7893 - precision_1: 0.8217 - recall_1: 0.7548 - val_loss: 0.6987 - val_accuracy: 0.7580 - val_precision_1: 0.7905 - val_recall_1: 0.7265\n"
          ]
        }
      ]
    }
  ]
}